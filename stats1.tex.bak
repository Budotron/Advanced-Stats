\documentclass[10pt]{article}
\usepackage{times}
\usepackage[bw, framed]{mcode}
\usepackage[cm]{fullpage}
\usepackage{cancel}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows,shapes}
\author{Varun Boodram}
\begin{document}
\begin{flushright}
Varun Boodram\\
81221544\\
\textsc{applied statistical analysis, assignment 1}
\end{flushright}
Problem 1.1: To show: $E_{\widehat{F}} (\widehat{se}^2_B)=\widehat{se}^2_{\infty}$
\begin{align*}
\widehat{se}_B&\overset{\mathclap{def}}=
\sqrt{\frac{\sum\limits_{b=1}^B\left[\hat{\theta^*}(b)-\hat{\theta^*}(\cdot)\right]^2}{B-1}} \\
\intertext {where $\hat{\theta^*}(\cdot)=\sum\limits_{b=1}^B \hat{\theta}^*(b)/B$ }
(B-1)\widehat{se}^2_B&=
\sum\limits_{b=1}^B\left[\hat{\theta}^*(b)-\hat{\theta}^*(\cdot)\right]^2\\
(B-1)E_{\widehat{F}}\left(\widehat{se}^2_B\right)&=
E_{\widehat{F}}\left\lbrace\sum\limits_{b=1}^B\left[
\hat{\theta}^*(b)^2-2\hat{\theta}^*(b)\hat{\theta}^*(\cdot)+
\hat{\theta}^*(\cdot)^2\right]\right\rbrace\\
&=E_{\widehat{F}}\left\lbrace\sum\limits_{b=1}^B
\hat{\theta}^*(b)^2-2\hat{\theta}^*(\cdot)\sum\limits_{b=1}^B\hat{\theta}^*(b)+
\hat{\theta}^*(\cdot)^2\sum\limits_{b=1}^B 1\right\rbrace\\
\shortintertext{$\because \sum\limits_{b=1}^B \hat{\theta}^*(b)=B \hat{\theta^*}(\cdot)  :$ }
&=E_{\widehat{F}}\left\lbrace\sum\limits_{b=1}^B
\hat{\theta}^*(b)^2-2B\hat{\theta}^*(\cdot)^2+
B\hat{\theta}^*(\cdot)^2\right\rbrace\\
&=\sum\limits_{b=1}^BE_{\widehat{F}}\left[\hat{\theta}^*(b)^2\right]-BE_{\widehat{F}}\left[\hat{\theta}^*(\cdot)^2\right]\\
\frac{B-1}{B} E_{\widehat{F}}\left(\widehat{se}^2_B\right)&=E_{\widehat{F}}\left[\hat{\theta}^*(b)^2 \right]-E_{\widehat{F}}\left[\hat{\theta}^*(\cdot)^2\right]\\
\smallskip
\intertext{As $E\left(\hat{\theta}^*(\cdot)\right)=E\left[\frac{1}{B}\sum\limits_{b=1}^B\hat{\theta}^*(b)\right]$,}
\frac{B-1}{B} E_{\widehat{F}}\left(\widehat{se}^2_B\right)&=E_{\widehat{F}}\left[\hat{\theta}^*(b)^2 \right]-E_{\widehat{F}}\left[\left(\frac{1}{B}\sum\limits_{b=1}^B\hat{\theta}^*(b)\right)^2\right]\\
\shortintertext{using $Var(X)=E(X^2)-E(X)^2$,}
&=E_{\widehat{F}}
\left[\hat{\theta}^*(b)^2 \right]
-\left\lbrace 
var_{\hat{F}}
\left[\frac{1}{B}
	\sum\limits_{b=1}^B
	\hat{\theta}^*(b)
\right]+
\left[
	E_{\hat{F}}
		\left(\frac{1}{B}
		\sum\limits_{b=1}^B
		\hat{\theta}^*(b)
		\right)
\right]^2
\right\rbrace\\
&=
E_{\hat{F}}
	\left[
		\hat{\theta}^*(b)^2
	\right]
-
	\frac{B}{B^2}var_{\hat{F}}
		\left[
			\hat{\theta}^*(b)
		\right]
-
\frac{B^2}{B^2}E_{\hat{F}}
	\left[
		\hat{\theta}^*(b)
	\right]^2\\
&=
E_{\hat{F}}
	\left[
		\hat{\theta}^*(b)^2
	\right]
-\frac{1}{B}
	\left\lbrace
		E_{\hat{F}}
			\left[
				\hat{\theta}^*(b)^2
			\right]
		-E_{\hat{F}}
			\left[
				\hat{\theta}^*(b)
			\right]^2
	\right\rbrace
-
E_{\hat{F}}
	\left(
		\hat{\theta}^*(b)
	\right)^2\\
\frac{B-1}{B}E_{\widehat{F}}
	\left(
		\widehat{se}_B^2
	\right)
&=
\frac{B-1}{B}
	\left\lbrace
		E_{\hat{F}}
			\left[
				\hat{\theta}^*(b)^2
			\right]
		-E_{\widehat{F}}
			\left[
				\hat{\theta^*}(b)
			\right]^2
	\right\rbrace\\
E_{\widehat{F}}
	\left(
		\widehat{se}_B^2
	\right)
&=
E_{\hat{F}}
	\left[
		\hat{\theta}^*(b)^2
	\right]
-E_{\widehat{F}}
	\left[
		\hat{\theta^*}(b)
	\right]^2\\
&=
\widehat{se}_{\infty}^2
\end{align*}
\clearpage
Problem 1.2. I could not figure out the proofs\\
\smallskip

Problem 1.3, a--b\\

(\underline{Apology}: I believe that the purpose of this exercise was to gain experience with R. I'm sorry, but as I was late for the workshop, and am unfamiliar with R, I implemented this problem in \textsc{matlab} instead)\\
Parts a) and b) are answered with the \textsc{matlab} code below, the results of which are summarized in the table following.\\
\lstinputlisting{/Users/varunboodram/Desktop/Stats/stats6_10_2.m}
Results:\\
\begin{center}
\begin{tabular}{|c|cccccc|}
\hline
B & 25& 100 & 200&500 & 1000 & 2000 \\ \hline
Rep 1 &  2.1793 &  2.2197 &  2.4482 &  2.5201 &  2.4345 &  2.4899 \\
Rep 2 & 2.2588   & 2.4288 &   2.4339 &   2.5597 &   2.4150 & 2.4410 \\
Rep 3 & 2.5391   &2.5380 &  2.4625 &  2.4407 &  2.4652 &   2.4744\\
Rep 4 & 2.4987  & 2.2715 &   2.5958 &   2.4404 &   2.4884 &   2.4460\\
Rep 5 & 2.4037 &  2.7881  &  2.3725 &   2.5587 &   2.5571 &   2.4334\\
Rep 6 & 3.0570   & 2.6595&    2.5592 &   2.5579  &  2.3933  & 2.5072\\
Rep 7 & 2.3581 & 2.3190 & 2.6926 & 2.4785 & 2.4336   & 2.4520\\
Rep 8 & 2.1465 &  2.2970 & 2.4075 & 2.5568 & 2.4159 & 2.5110\\
Rep 9 & 1.8816 &  2.7691 &  2.5510 &  2.4004 &  2.4727 &  2.4652\\
Rep 10 & 1.8590 &  2.4514 &  2.3945 &  2.3993 &  2.4813 &  2.4506\\ \hline
Standard Error & 0.3480 & 0.2076 & 0.1033 & 0.0673 &0.0477 &0.0276\\
\hline
\end{tabular}
\end{center}
a) From the last entry on the first row, the ideal bootstrap estimate $\widehat{se}_{\infty}^2$ can be estimated at $2.49$. \\
b) From the final row of the table, it is clear that if a standard error of $0.05$ is required, $B \geq 1000$ will acheive this accuracy. \\

Problem 1.4\\

We are asked to calculate the standard error for $B$, as in problem 1.3, and assess the variability in the estimates, where $\theta$, the statistics of interest are the mean and the median. This is easily accomplished by replacing \texttt{trimmean(X(:,k), 50)} with \texttt{mean(X(:,k))}, and \texttt{median(X(:,k))}, in the code above, as shown below: 
\lstinputlisting{/Users/varunboodram/Desktop/Stats/stats6_10_2a.m}
The results of this computation are summarized below:
\begin{center}
\begin{tabular}{|c|cccccc|}
\hline
B & 25& 100 & 200&500 & 1000 & 2000 \\ \hline
Rep 1 &  1.6466  & 2.0663  & 1.8939  & 1.8704   &1.9139  & 1.8853 \\
Rep 2 & 1.6692  & 1.7996 &  1.7953 &  1.8934&   1.8991&   1.9339 \\
Rep 3 & 2.0421  & 1.7497&   1.8628&   1.8167&  1.9182&   1.8759\\
Rep 4 &  2.0703  & 2.0749&   1.7325&   1.9203 &  1.8194 &  1.8871\\
Rep 5 & 2.1507 &  2.0153&   2.1360  & 1.8748 &  1.8301 &  1.9065\\
Rep 6 & 1.8387  & 1.8912  & 1.8519  & 1.9028 &  1.9548  & 1.8881\\
Rep 7 & 1.9896  & 1.9464 &  1.7731  & 1.9111   &1.8581 &  1.9083\\
Rep 8 & 1.9146  & 2.0498  & 1.8284  & 1.8934 &  1.9114   &1.9204\\
Rep 9 & 1.8374  & 1.7516  & 1.8983   &1.8347  & 1.9242 &  1.8712\\
Rep 10 & 0.2064  & 0.1276 &  0.1112  & 1.9503 &  1.9198   &1.9123\\ \hline
Standard Error & 0.3480 & 0.2076 & 0.1033 & 0.0396 &0.0441 &
    0.0204\\
\hline
\end{tabular}
\end{center}
As before, the final entry of the first row gives the estimate of $\widehat{se}_{\infty}^2=1.89$, and it is clear from the last row that if we deisre a standard error of less than 0.05, $B \geq 2000$ will acheive the deired accuracy.\\
Replacing \texttt{mean} in the above code with \texttt{median} produces the following results: 
\begin{center}
\begin{tabular}{|c|cccccc|}
\hline
B & 25& 100 & 200&500 & 1000 & 2000 \\ \hline
Rep 1 &  2.4176  & 3.0296&   2.6706  & 2.7910 &  2.7783 &  2.7897 \\
Rep 2 & 2.4968   &2.4870   &2.4541   &2.6032  & 2.8685   &2.7757
 \\
Rep 3 &2.7702   &2.5824 &  2.7609  & 2.6636 &  2.8011  & 2.8041\\
Rep 4 &  3.0334   &2.7130 &  2.7830   &2.5887   &2.7182  & 2.8083\\
Rep 5 &2.4521 &  3.0956  & 2.7023  & 2.8193 &  2.7961  & 2.7427\\
Rep 6 & 3.0608   &2.6093  & 2.6392  & 2.6912 &  2.7221  & 2.6851\\
Rep 7 & 2.8112  & 2.5403  & 2.4944   &2.7033 &  2.7386  & 2.7277\\
Rep 8 & 2.3241   &2.9202 &  2.6606  & 2.8441  & 2.7873  & 2.7533\\
Rep 9 & 3.1417  & 2.8389  & 2.7300&  2.6807  & 2.7410  & 2.7211\\
Rep 10 & 2.5546 & 2.7646 & 2.7626 & 2.7159 & 2.6157&  2.7149\\ \hline
Standard Error &  0.2978 & 0.2099 & 0.1118 & 0.0857 &0.0671 &
  0.0413\\
\hline
\end{tabular}
\end{center}
In this case, the estimate of $\widehat{se}_{\infty}^2$ is 2.79, and $B \geq 2000$ allows us to acheive a standard error of 0.05. \\
To compare the accuracies of the statistics, we use the coefficient of variation, $cv=\frac{\sigma}{\mu}$ in the formula $cv(\widehat{se}_B)\approx
	\left\lbrace
		cv(\widehat{se}_{\infty}^2)+\frac{E(\Delta)+2}{4B}
	\right\rbrace^{1/2}$.
\end{document}
